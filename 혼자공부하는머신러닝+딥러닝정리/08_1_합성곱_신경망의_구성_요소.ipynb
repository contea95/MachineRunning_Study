{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08-1_합성곱 신경망의 구성 요소.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YavazTn3hXDN"
      },
      "source": [
        "## 합성곱\n",
        "7장에서 사용한 밀집층에는 뉴런마다 입력 개수만큼의 가중치가 있다. 즉 모든 입력에 가중치를 곱한다.\n",
        "\n",
        "인공 신경망은 처음에 가중치 w1~w10과 절편 b를 랜덤하게 초기화한 다음 에포크를 반복하면서 경사 하강법 알고리즘을 사용하여 손실이 낮아지도록 최적의 가중치와 절편을 찾아간다.\n",
        "\n",
        "합성곱은 밀집층의 계산과 달리 입력 데이터 전체에 가중치를 적용하는 것이 아니라 일부에 가중치를 곱한다.\n",
        "\n",
        "예를 들면 가중치 w1~w3이 입력의 처음 3개 특성과 곱해져 1개의 출력을 만든다. 그 다음 이 뉴런이 한칸 아래로 이동해 두번째 부터 네 번째 특성과 곱해져 새로운 출력을 만든다.\n",
        "\n",
        "여기에서 중요한 것은 첫번째 합성곱에 사용된 가중치 w1~w3과 절편 b가 두번째 합성곱에도 동일하게 사용된다. 이렇게 한 칸씩 아래로 이동하면서 출력을 만드는 것이 합성곱이다. 여기에서는 이 뉴런의 가중치가 3개이기 때문에 모두 8개의 출력이 만들어진다.\n",
        "(여기서 w1,w2,w3은 같고 곱하는 수는 다르다.)\n",
        "\n",
        "밀집층의 뉴런은 입력 개수만큼 10개의 가중치를 가지고 1개의 출력을 만든다. 합성곱 층의 뉴런은 3개의 가중치를 가지고 8개의 출력을 만든다. 이는 하이퍼 파라미터로 바꿀 수 있다.\n",
        "\n",
        "합성곱 신경망(CNN)에서는 완전 연결 신경망과 달리 뉴런을 필터라고 부른다. 혹은 커널이라고도 한다.\n",
        "\n",
        "합성곱은 2차원 입력에도 적용할 수 있다. 예를 들어 입력이 2차원이면, 필터도 2차원으로 주어져야 한다. 그리고 필터의 크기는 (3,3)으로 가정한다.(이는 하이퍼 파라미터로 바꿀 수 있다) 그 다음 왼쪽 위 모서리부터 합성곱을 시작한다. 입력의 9개의 원소와 커널의 9개 가중치를 곱한 후(절편 포함해서 더한다.) 1개의 출력을 만든다.\n",
        "\n",
        "그 다음 필터가 오른쪽으로 한 칸 이동하여 합성곱을 또 수행한다. 입력의 너비가 4이므로 더이상 오른쪽으로 갈 수 없다. 이때ㅔ는 아래로 한칸 이동한 다음 다시 왼쪽부터 합성곱을 수행한다.\n",
        "\n",
        "필터는 모두 4번 이동하였기 때문에 4개의 출력을 만들 수 있다.\n",
        "\n",
        "이때 4개의 출력을 필터가 입력에 놓인 위치에 맞게 2차원으로 배치한다. 즉 왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래 모두 34개의 위치에 해당 값을 놓는다. 이렇게 합성곱 계산을 통해 얻게된 출력을 특성 맵이라고 한다.\n",
        "\n",
        "밀집층에서 여러 뉴런을 사용하듯 합성곱 층에서도 여러개의 필터를 사용한다. (2,2) 크기의 특성 맵을 쌓으면 3차원 배열이 되는데 예를 들어 3개의 필터를 사용하면 (2,2,3)크기의 3차원 배열이 된다.\n",
        "\n",
        "## 케라스 합성곱 층\n",
        "케라스의 층은 모두 keras.layers 패키지 아래 클래스로 구현되어 있다. 입력을 위에서 아래로, 왼쪽에서 오른쪽으로 이동하는 합성곱은 Conv2D클래스로 제공한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK6AWzDlZHso",
        "outputId": "cfc07eda-dd9c-453b-bcf8-9e8212452359"
      },
      "source": [
        "from tensorflow import keras\n",
        "keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7f160245fa20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p108yXjHfr22"
      },
      "source": [
        "Conv2D 클래스의 처음 매개변수는 필터 개수, 두번째는 필터에 사용할 커널의 크기, 마지막으로 밀집층에서 사용하는 활성화 함수 지정이다.\n",
        "\n",
        "이전에 Dense층을 사용하던 자리에 Conv2D층을 넣으면 된다. 다만 kernel_size와 같은 추가적인 매개변수들을 고려해야 한다.\n",
        "\n",
        "### 패딩과 스트라이드\n",
        "앞서 예로 들었던 합성곱 계산은 (4,4) 크기의 입력에 (3,3) 크기의 커널을 적용해 (2,2) 크기의 특성맵을 만들었다. 커널의 크기는 (3,3)으로 두고 출력의 크기를 입력과 동일하게 (4,4)로 만들기 위해서는 어떻게 해야할까?\n",
        "\n",
        "(4,4) 입력과 동일한 크기의 출력을 만들려면 더 큰 입력에 합성곱을 하는 척해야 한다. 실제 입력 크기가 (4,4)지만 (6,6)처럼 만들었다고 하고 합성곱을 수행하면 (4,4)크기의 출력을 만들 수 있다.\n",
        "\n",
        "이렇게 입력 배열 주위를 가상의 원소로 채우는 것을 패딩이라고 한다. 실제 입력값이 아니기 대문에 패딩은 0으로 채운다. 실제 값은 0으로 채워져 있기 때문에 계산에 영향을 미치지 않는다.\n",
        "\n",
        "이렇게 입력과 특성 맵의 크기를 동일하게 만들기 위해 입력 주위에 0으로 패딩하는 것을 세임 패딩이라고 부른다. 합성곱 신경망에서는 세임 패딩이 많이 사용된다.\n",
        "\n",
        "패딩 없이 순수한 입력 배열에서만 합성곱을 하여 특성 맵을 만드는 경우를 밸리드 패딩이라고 한다. 밸리드 패딩은 특성 맵의 크기가 줄어들 수밖에 없다.\n",
        "\n",
        "왜 합성곱에서는 패딩을 자주 사용할까? 아까와 같이 (4,4)크기 입력, (3,3)크기의 커널을 적용해 (2,2) 크기의 특성 맵을 만든다고 하면 가운데 2*2 크기의 픽셀이 4번 계산에 포함된다. 이 입력을 이미지라고 생각하면 모서리에 있는 중요한 정보가 특성 맵으로 잘 전달이 되지 않을 가능성이 높다. 패딩을 적용하면 가운에 픽셀은 9번 계산에 참여하지만 모서리에 있는 픽셀은 4번으로 전보다 참여하는 비율이 줄어들거나,동일해진다.\n",
        "\n",
        "적절한 패딩은 이처럼 이미지 주변에 있는 정보를 잃어버리지 않도록 도와준다. Conv2D클래스에서는 padding 매개변수로 패딩을 지정할 수 있다. 기본값은 'valid'로 밸리드 패딩을 나타내고 세임 패딩을 사용하려면 'same'으로 바꾸면 된다.\n",
        "\n",
        "    keras.layers.Conv2D(10, kernel_size(3,3), activation='relu', padding='same')\n",
        "\n",
        "합성곱 연산은 한칸씩 이동하지만 두칸씩 이동할 수도 있다. 이런 이동의 크기를 스트라이드라고 한다. 기본적으로 스트라이드는 1이고 strides 매개변수로 바꿀 수 있다.\n",
        "\n",
        "    keras.layers.Conv2D(10, kernel_size=(3,3), activation='relu',strides=1)\n",
        "\n",
        "strides 매개변수는 (1,2)처럼 튜플로 지정도 가능하다. 이는 (오른쪽으로 이동하는 크기, 아래로 이동하는 크기) 를 나타낸다.\n",
        "\n",
        "### 풀링\n",
        "풀링은 합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄이는 역할을 수행한다. 하지만 특성 맵의 개수는 줄이지 않는다. 예를 들어 (2,2,3) 크기의 특성 맵에 풀링을 적용하면 마지막 차원인 개수는 그대로 유지하고 너비와 높이만 줄어들어 (1,1,3) 크기의 특성 맵이 된다.\n",
        "\n",
        "풀링도 합성곱처럼 입력 위를 지나가면서 도장을 찍는 것이다. 위 그림에서는 (2,2)크기로 풀링을 한다. 하지만 풀링에는 가중치가 없어 영역에서 가장 큰 값을 고르거나 평균값을 계산한다. 이를 각각 최대 풀링, 평균 풀링이라고 한다.\n",
        "\n",
        "가령 (4,4)크기의 특성 맵이 있다고 가정하고, (2,2) 최대풀링을 적용하면 절반으로 크기가 줄어든다.\n",
        "\n",
        "최대 풀리은 가장 큰 값을 고르기 때문에 첫번째 (2,2)영역에서 9를 고르고, 그 다음 7,8,6을 차례대로 골라 (2,2) 크기의 출력을 만든다. 특성 맵이 여러 개라면 동일한 작업을 반복한다. 즉 10개의 특성맵이 있으면 풀링을 거친 특성맵도 10개가 된다.\n",
        "\n",
        "풀링 영역은 겹치지 않고 이동해서 스트라이드가 풀링의 크기와 똑같다.\n",
        "\n",
        "풀링은 가중치가 없고 풀링 크기와 스트라이드가 같기 때문에 이해가 쉽다. 케라스에서는 MaxPooling2D 클래스로 풀링을 수행할 수 있다.\n",
        "\n",
        "    keras.layers.MaxPooling2D(2)\n",
        "\n",
        "MaxPooling2D의 첫 번째 매개변수로 풀링의 크기를 지정한다. 대부분 풀링의 크기는 2이다. 즉 가로세로 크기를 절반 줄인다. 가로세로 방향의 풀링 크기를 다르게 하려면 첫 번째 매개변수를 정수의 튜플로 지정할 수 있다.\n",
        "\n",
        "합성곱 층과 마찬가지로 strides나 padding 매개변수를 제공한다. strides의 기본값은 자동으로 풀링의 크기이므로 따로 지정할 필요가 없다. padding 의 기본값은 'valid'로 패딩을 하지 않는다. 풀링은 패딩을 하지 않기 때문이다.\n",
        "\n",
        "    keras.layers.MaxPolling2D(2, strides=2, padding='valid')\n",
        "\n",
        "평균 풀링을 제공하는 클래스는 AveragePolling2D이다. 최댓값 대신 평균을 계산하는 것이 최대 풀링과의 차이이며 동일한 매개변수를 가지고 있다. 대부분 평균 풀링보다 최대 풀링을 많이 사용한다. 평균 풀링은 특성 맵에 있는 중요 정보를 희석시킬 수 있기 때문이다.\n",
        "\n",
        "꼭 기억할 점은 풀링은 가로 세로 방향으로만 진행한다. 특성 맵의 개수는 변하지 않는다.\n",
        "\n",
        "## 합성곱 신경망의 전체 구조\n",
        "합성곱 층에서 사용할 커널 크기는 (3,3), 세임 패딩이므로 1픽셀이 입력 데이터 주변에 추가된 형태이다. 패딩이 추가된 입력에서 합성곱이 수행\n",
        "\n",
        "합성곱 필터가 3개라고 가정하자. 각각 (3,3)크기 가중치를 가지고 있고 필터마다 절편이 하나 존재한다. 이 가중치와 절편은 필터마다 서로 다르다.\n",
        "\n",
        "합성곱의 스트라이드는 기본적으로 1이다. 만들어지는 특성 맵의 크기는 (4,4)이다. 3개의 필터가 하나씩 합성곱의 출력을 만들고 이 출력이 합쳐져 (4,4,3)크기의 특성 맵이 만들어진다. 밀집층과 마찬가지로 합성곱 층에서도 활성화 함수를 적용한다. 합성곱 층은 활성화 함수로 렐루 함수를 많이 사용한다.\n",
        "\n",
        "그 다음은 풀링층 이다. 풀링 층은 합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄인다. 보통 (2,2) 풀링을 사용해 절반으로 줄인다. 특성 맵의 개수는 변하지 않아 (4,4,3) 에서 (2,2,3)으로 변한다.\n",
        "\n",
        "풀링을 사용하는 이유는 합성곱에서 스트라이드를 크게 하여 특성 맵을 줄이는 것보다 풀링층에서 크기를 줄이는 것이 더 나은 성능을 내기 때문이다. 합성곱 신경망은 이렇게 합성곱 층에서 특성 맵을 생성, 풀링에서 크기를 줄이는 구조로 이루어져있다.\n",
        "\n",
        "풀링을 거친 특성 맵의 크기는 절반으로 줄어 (2,2,3)이 된다. 밀집층인 출력층에서 계산된 값은 소프트맥스 활성화 함수를 거쳐 최종 예측 확률이 된다.\n",
        "\n",
        "### 컬러 이미지를 사용한 합성곱\n",
        "지금까지는 입력을 2차원 배열로 가정했다. 이 장에서 다룰 패션MNIST 데이터는 실제로 흑백 이미지이기 대문에 2차원 배열로 표현, 하지만 컬러 이미지는 다르다. RGB 채널로 구성되어 있기 때문에 3차원 배열로 표시해야 한다.\n",
        "\n",
        "하나의 컬라 이미지는 너비와 높이 차원 외에 깊이 차원(채널 차원)이 있다. 예를 들어 입력이 (4,4)가 아닌 (4,4,3)으로 이루어져 있다.\n",
        "\n",
        "깊이가 있는 입력에서 합성곱을 수행하기 위해서는 도장도 깊이가 필요하다. 즉 필터 크기가 (3,3)이 아니라 (3,3,3)이 된다. 커널 배열의 깊이는 입력 깊이와 같다.\n",
        "\n",
        "이 합성곱의 계산은 (3,3,3) 영역에 해당하는 27개의 원소에 27개의 가중치를 곱하고 절편을 더하는 식이 된다. (4,4,3) 크기 입력과 (3,3,3) 크기의 커널의 합성곱을 통한 (2,2)크기의 특성 맵이 출력.\n",
        "\n",
        "여기서 중요한 것은 입력이나 커널의 차원이 몇 개인 지 상관없이 항상 출력 차원은 1개라는 점이다.\n",
        "\n",
        "이와 비슷한 경우는 합성곱 층 - 풀링 층 다음 다시 합성곱 층이 올 때이다. 예를 들어 첫번째 합성곱 층의 필터의 개수가 5개라 가정한다. 첫번째 풀링층을 통과한 특성 맵의 크기가 (4,4,5)라고 해보자.\n",
        "\n",
        "두번째 합성곱 층에서 필터의 너비와 높이가 각각 3이라면 이 필터의 커널 크기는 (3,3,5)가 된다. 왜냐하면 입력의 깊이와 필터의 깊이는 같아야 하기 때문이다. 이 합성곱의 결과는 1개의 출력을 만든다.\n",
        "\n",
        "두번째 합성곱 층의 필터 개수가 10개라면 만들어진 특성 맵의 크기는 (2,2,10)이 될 것이다.(필터 개수가 10개라서 10개로) 이렇게 합성곱 신경망은 너비와 높이는 점점 줄어들고 깊이는 깊어지는 것이 특징이다. 그리고 마지막 출력층 전에 특성 맵을 모두 펼쳐 밀집층의 입력으로 사용한다.\n",
        "\n",
        "합성곱 신경망에서 필터는 이미지에 있는 특징을 찾는다고 생각할 수 있다. 처음에는 간단한 기본적인 직선, 곡선같은 특징을 찾고 층이 깊어질수록 다양하고 구체적인 특징을 감지할 수 있도록 필터의 개수를 늘린다. 또 어떤 특징이 이미지의 어느 위치에 놓이더라도 쉽게 감지할 수 있도록 너비와 높이 차원을 점점 줄여간다."
      ]
    }
  ]
}